import streamlit as st
import pandas as pd
import numpy as np
import re
import time # ìŠ¤í”¼ë„ˆ íš¨ê³¼ë¥¼ ìœ„í•´ ì¶”ê°€

# --- algo.ipynbì˜ ìŠ¤í¬ë˜í•‘/ë¶„ì„ ë¡œì§ì„ í•¨ìˆ˜ë¡œ ê°€ì ¸ì˜¤ê¸° ---
# (ì…€ 3: ìŠ¤í¬ë˜í•‘)
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# (ì…€ 5: ë¶„ì„ ë¡œì§ì— í•„ìš”í•œ í‚¤ì›Œë“œ ë° í•¨ìˆ˜ë“¤)
suspicious_keywords = [
    "ë‹¨ê¸°ì„ëŒ€", "ì €ê¸ˆë¦¬", "ëŒ€ì¶œì´ì", "ëŒ€ì¶œ ì•Œì„ ", "ì‹¤ì…ì£¼ê¸ˆ", "ì‹¤ì…ì£¼ ê¸ˆì•¡",
    "ë‹¹ì¼ê³„ì•½", "ê³„ì•½ ì„œë‘ë¥´ì„¸ìš”", "ë³´ì¦ê¸ˆ ëŒ€ë‚©"
]

include_keywords = {
    "ìˆ˜ë„": ["ìˆ˜ë„", "ìˆ˜ë„ë£Œ"],
    "ì¸í„°ë„·/TV": ["ì¸í„°ë„·", "IPTV", "ì™€ì´íŒŒì´", "wifi"],
    "ì „ê¸°": ["ì „ê¸°ì„¸", "ì „ê¸° ìš”ê¸ˆ", "ì „ê¸°", "ê³µìš©ì „ê¸°"],
    "ê°€ìŠ¤/ë‚œë°©": ["ê°€ìŠ¤", "ë„ì‹œê°€ìŠ¤", "ë‚œë°©"],
    "ì²­ì†Œ/ê´€ë¦¬": ["ì²­ì†Œ", "ì²­ì†Œë¹„", "ì¼ë°˜ê´€ë¦¬ë¹„", "ê´€ë¦¬ë¹„ í¬í•¨"],
    "ì£¼ì°¨": ["ì£¼ì°¨ í¬í•¨", "ì£¼ì°¨ë¹„ í¬í•¨"],
    "ì—˜ë¦¬ë² ì´í„°/ê±´ë¬¼": ["ì—˜ë¦¬ë² ì´í„°", "ê±´ë¬¼ìœ ì§€ë¹„", "ê³µìš©ê´€ë¦¬ë¹„"]
}

# --- í—¬í¼ í•¨ìˆ˜ (ìˆ«ì ë³€í™˜, í‚¤ì›Œë“œ ì¹´ìš´íŠ¸ ë“±) ---

def to_float(x):
    if pd.isna(x): return np.nan
    return float(str(x).replace(",", ""))

def calc_price_risk(row):
    risk = 0
    if pd.notna(row["ë³´ì¦ê¸ˆë¹„ìœ¨"]):
        if row["ë³´ì¦ê¸ˆë¹„ìœ¨"] <= 0.7: risk += 4
        elif row["ë³´ì¦ê¸ˆë¹„ìœ¨"] <= 0.8: risk += 2
    if pd.notna(row["ì›”ì„¸ë¹„ìœ¨"]):
        if row["ì›”ì„¸ë¹„ìœ¨"] <= 0.7: risk += 4
        elif row["ì›”ì„¸ë¹„ìœ¨"] <= 0.8: risk += 2
    return risk

# (ì•± ê°œì„ : ì–´ë–¤ í‚¤ì›Œë“œê°€ ê±¸ë ¸ëŠ”ì§€ë„ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •)
def analyze_keywords(text):
    if pd.isna(text):
        return 0, []
    text = str(text)
    found_kws = [kw for kw in suspicious_keywords if kw in text]
    return len(found_kws), found_kws

def parse_manage_fee(manage_fee_str):
    if manage_fee_str is None or pd.isna(manage_fee_str): return np.nan
    text = str(manage_fee_str)
    if "í™•ì¸ë¶ˆê°€" in text: return np.nan
    m = re.search(r"([\d\.]+)\s*ë§Œì›", text)
    if not m: return np.nan
    return float(m.group(1)) * 10000

def extract_manage_includes(desc):
    if desc is None or pd.isna(desc): return []
    text = str(desc)
    found = []
    for label, kws in include_keywords.items():
        for kw in kws:
            if kw in text:
                found.append(label)
                break
    return list(set(found))

def calc_manage_fee_risk(manage_fee_str, desc):
    fee = parse_manage_fee(manage_fee_str)
    includes = extract_manage_includes(desc)
    cnt = len(includes)
    risk, label = 0, "ì •ìƒ"
    
    if fee is np.nan or pd.isna(fee):
        risk = 3; label = "ìœ„í—˜"
    elif fee < 80000:
        risk = 0; label = "ì •ìƒ"
    elif fee < 110000:
        if cnt < 2: risk = 1; label = "ì£¼ì˜"
    elif fee < 150000:
        if cnt < 3: risk = 2; label = "ìœ„í—˜"
        else: risk = 1; label = "ì£¼ì˜"
    else:
        if cnt < 4: risk = 3; label = "ìœ„í—˜"
        else: risk = 2; label = "ì£¼ì˜"
    
    return risk, label, includes, cnt

# --- @st.cache_resource: ì›¹ë“œë¼ì´ë²„ëŠ” í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ ìºì‹œ ---
@st.cache_resource
def get_driver():
    options = Options()
    options.add_argument("--headless") 
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    # Streamlit Cloudì— ì„¤ì¹˜ëœ chromedriverì˜ ê²½ë¡œë¥¼ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.
    driver = webdriver.Chrome(
        service=Service('/usr/bin/chromedriver'), 
        options=options
    )
    return driver

# --- @st.cache_data: 'dong_ss.csv' íŒŒì¼ì€ í•œ ë²ˆë§Œ ì½ë„ë¡ ìºì‹œ ---
@st.cache_data
def load_avg_data():
    try:
        return pd.read_csv("dong_ss.csv")
    except FileNotFoundError:
        st.error("ì˜¤ë¥˜: 'dong_ss.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! app.pyì™€ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        return None

# --- 1. ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (URL ì…ë ¥ë°›ê¸°) ---
def scrape_zigbang_data(url, driver):
    driver.get(url)
    wait = WebDriverWait(driver, 10)
    
    # 1) ì£¼ì†Œ + ê´€ë¦¬ë¹„
    loc_text = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.css-1563yu1'))).text.strip()
    if " Â· " in loc_text:
        address, manage_fee = loc_text.split(" Â· ", 1)
    else:
        address, manage_fee = loc_text, None

    # 2) í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸
    full = driver.find_element(By.TAG_NAME, "body").text
    
    # 3) ë³´ì¦ê¸ˆ / ì›”ì„¸
    m = re.search(r"ì›”ì„¸\s*([\d,]+)\s*/\s*([\d,]+)", full)
    deposit, rent = (m.group(1), m.group(2)) if m else (None, None)

    # 4) ì „ìš©ë©´ì 
    area_match = re.search(r"ì „ìš©\s*([\d\.]+)mÂ²", full)
    area = area_match.group(1) if area_match else None

    # 5) ìƒì„¸ì„¤ëª…
    start_idx = None
    for key in ["ìƒì„¸ ì„¤ëª…", "íŠ¹ì§• ë° ê¸°íƒ€ ì‚¬í•­"]:
        if key in full: start_idx = full.index(key); break
    
    if start_idx is not None:
        desc_full = full[start_idx:]
        end_idx = desc_full.find("ë”ë³´ê¸°")
        desc = desc_full[:end_idx].strip() if end_idx != -1 else desc_full.strip()
    else:
        desc = None

    row = {
        "ì£¼ì†Œ": address, "ê´€ë¦¬ë¹„": manage_fee, "ë³´ì¦ê¸ˆ": deposit,
        "ì›”ì„¸": rent, "ì „ìš©ë©´ì ": area, "ìƒì„¸ì„¤ëª…": desc
    }
    return pd.DataFrame([row])

# --- 2. ìœ„í—˜ë„ ë¶„ì„ í•¨ìˆ˜ ---
def analyze_risk_data(df, avg_df):
    merged = df.copy()
    
    # 2. ë™ ì¶”ì¶œ
    merged["ë™"] = merged["ì£¼ì†Œ"].str.extract(r"(\S+ë™)")
    
    # 3. ìˆ«ì ë³€í™˜
    merged["ë³´ì¦ê¸ˆ_num"] = merged["ë³´ì¦ê¸ˆ"].apply(to_float)
    merged["ì›”ì„¸_num"] = merged["ì›”ì„¸"].apply(to_float)
    
    # 4. í‰ê·  ì‹œì„¸ merge
    merged = merged.merge(avg_df, on="ë™", how="left")
    
    # 5. ë¹„ìœ¨ ê³„ì‚°
    merged["ë³´ì¦ê¸ˆë¹„ìœ¨"] = merged["ë³´ì¦ê¸ˆ_num"] / merged["í‰ê· ë³´ì¦ê¸ˆ"]
    merged["ì›”ì„¸ë¹„ìœ¨"] = merged["ì›”ì„¸_num"] / merged["í‰ê· ì›”ì„¸"]
    
    # 6. ê°€ê²© ìœ„í—˜ ì ìˆ˜
    merged["ê°€ê²©ìœ„í—˜ì ìˆ˜"] = merged.apply(calc_price_risk, axis=1)
    
    # 7. í‚¤ì›Œë“œ ìœ„í—˜ ì ìˆ˜ (ê°œì„ ëœ í•¨ìˆ˜ ì ìš©)
    kw_results = merged["ìƒì„¸ì„¤ëª…"].apply(analyze_keywords)
    merged["í‚¤ì›Œë“œìœ„í—˜ê°œìˆ˜"] = kw_results.apply(lambda x: x[0])
    merged["ë°œê²¬í‚¤ì›Œë“œ"] = kw_results.apply(lambda x: x[1])

    # 8. ê´€ë¦¬ë¹„ ìœ„í—˜ ì ìˆ˜
    manage_risks = merged.apply(
        lambda row: calc_manage_fee_risk(row["ê´€ë¦¬ë¹„"], row["ìƒì„¸ì„¤ëª…"]), axis=1
    )
    merged["ê´€ë¦¬ë¹„ìœ„í—˜ì ìˆ˜"] = manage_risks.apply(lambda x: x[0])
    merged["ê´€ë¦¬ë¹„íŒì •"] = manage_risks.apply(lambda x: x[1])
    merged["ê´€ë¦¬ë¹„í¬í•¨í•­ëª©"] = manage_risks.apply(lambda x: x[2])

    # 9. ì´ ìœ„í—˜ ì ìˆ˜ & ë“±ê¸‰ (â€» ë…¸íŠ¸ë¶ ì½”ë“œ ìˆ˜ì •: ê´€ë¦¬ë¹„ ì ìˆ˜ë„ ì´ì ì— í¬í•¨!)
    merged["ì´ìœ„í—˜ì ìˆ˜"] = merged["ê°€ê²©ìœ„í—˜ì ìˆ˜"] + merged["í‚¤ì›Œë“œìœ„í—˜ê°œìˆ˜"] + merged["ê´€ë¦¬ë¹„ìœ„í—˜ì ìˆ˜"]
    
    merged["ìœ„í—˜ë“±ê¸‰"] = pd.cut(
        merged["ì´ìœ„í—˜ì ìˆ˜"],
        bins=[-1, 3, 7, 12, 20],      
        labels=["ë‚®ìŒ", "ë³´í†µ", "ì£¼ì˜", "ìœ„í—˜"]
    )
    
    return merged.iloc[0] # ì²« ë²ˆì§¸ (ìœ ì¼í•œ) í–‰ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜

# ==========================================================
#  streamlit ì•± UI ë¶€ë¶„
# ==========================================================

st.title("ğŸ•µï¸ ì§ë°© ë§¤ë¬¼ ìœ„í—˜ë„ ë¶„ì„ê¸°")
st.write("ë¶„ì„í•˜ê³  ì‹¶ì€ ì§ë°© ì›ë£¸/ì˜¤í”¼ìŠ¤í…”ì˜ 'ê³µìœ í•˜ê¸°' URLì„ ì…ë ¥í•˜ì„¸ìš”.")

# 1. 'dong_ss.csv' ë¡œë“œ
avg_df = load_avg_data()

# 2. URL ì…ë ¥ì°½
url = st.text_input("ì§ë°© URLì„ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:", placeholder="https://sp.zigbang.com/share/oneroom/...")

# 3. ë¶„ì„ ë²„íŠ¼
if st.button("ìœ„í—˜ë„ ë¶„ì„ ì‹œì‘í•˜ê¸° ğŸš€") and avg_df is not None:
    if "zigbang.com" not in url:
        st.error("ì˜¬ë°”ë¥¸ ì§ë°©(zigbang.com) URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        try:
            # 4. ìŠ¤í”¼ë„ˆ ì‹¤í–‰ (ë¡œë”© ì¤‘ í‘œì‹œ)
            with st.spinner("ë§¤ë¬¼ ì •ë³´ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê³  ìœ„í—˜ë„ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                driver = get_driver()
                scraped_df = scrape_zigbang_data(url, driver)
                result = analyze_risk_data(scraped_df, avg_df)
            
            st.success("ğŸ‰ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.divider() # --- êµ¬ë¶„ì„  ---

            # 5. ê²°ê³¼ í‘œì‹œ (ìš”ì²­í•˜ì‹  ë¶€ë¶„)
            
            # 5-1. ì£¼ì†Œ
            st.subheader(f"ğŸ  ì£¼ì†Œ: {result['ì£¼ì†Œ']}")
            
            # 5-2. ìœ„í—˜ë“±ê¸‰ ë° ì´ì 
            level = result['ìœ„í—˜ë“±ê¸‰']
            if level == 'ìœ„í—˜' or level == 'ì£¼ì˜':
                st.error(f"ğŸš¨ ìœ„í—˜ ë“±ê¸‰: {level}")
            elif level == 'ë³´í†µ':
                st.warning(f"âš ï¸ ìœ„í—˜ ë“±ê¸‰: {level}")
            else:
                st.success(f"âœ… ìœ„í—˜ ë“±ê¸‰: {level}")
            
            st.metric(label="ì´ ìœ„í—˜ ì ìˆ˜", value=f"{result['ì´ìœ„í—˜ì ìˆ˜']} ì ")
            
            
            # 5-3. ìœ„í—˜ ì ìˆ˜ ì„¸ë¶€ ë‚´ì—­ (ì ìˆ˜ê°€ ìƒê¸´ ë¶„ì•¼)
            st.subheader("ğŸ“ˆ ìœ„í—˜ ì ìˆ˜ ì„¸ë¶€ ë‚´ì—­")
            
            col1, col2, col3 = st.columns(3)
            col1.metric("ğŸ’° ê°€ê²© ì ìˆ˜", f"{result['ê°€ê²©ìœ„í—˜ì ìˆ˜']} ì ")
            col2.metric("ğŸ”‘ í‚¤ì›Œë“œ ì ìˆ˜", f"{result['í‚¤ì›Œë“œìœ„í—˜ê°œìˆ˜']} ì ")
            col3.metric("ğŸ§¾ ê´€ë¦¬ë¹„ ì ìˆ˜", f"{result['ê´€ë¦¬ë¹„ìœ„í—˜ì ìˆ˜']} ì ")

            # 5-4. (ì¶”ê°€) ì™œ ì ìˆ˜ê°€ ë‚˜ì™”ëŠ”ì§€ ìƒì„¸ ì„¤ëª…
            if result['ê°€ê²©ìœ„í—˜ì ìˆ˜'] > 0:
                st.caption(f"  - ë™ë„¤ í‰ê·  ëŒ€ë¹„ ê°€ê²©ì´ ë‚®ìŠµë‹ˆë‹¤. (ë³´ì¦ê¸ˆ ë¹„ìœ¨: {result['ë³´ì¦ê¸ˆë¹„ìœ¨']:.2f}, ì›”ì„¸ ë¹„ìœ¨: {result['ì›”ì„¸ë¹„ìœ¨']:.2f})")
            
            if result['í‚¤ì›Œë“œìœ„í—˜ê°œìˆ˜'] > 0:
                st.caption(f"  - ìƒì„¸ì„¤ëª…ì—ì„œ ë‹¤ìŒ ìœ„í—˜ í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤: **{', '.join(result['ë°œê²¬í‚¤ì›Œë“œ'])}**")
            
            if result['ê´€ë¦¬ë¹„ìœ„í—˜ì ìˆ˜'] > 0:
                st.caption(f"  - ê´€ë¦¬ë¹„ê°€ {result['ê´€ë¦¬ë¹„']}ì´ë©° '{result['ê´€ë¦¬ë¹„íŒì •']}' íŒì •ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            
            # 5-5. (ì°¸ê³ ) ì „ì²´ ë°ì´í„° ë³´ì—¬ì£¼ê¸° (ì„ íƒ ì‚¬í•­)
            with st.expander("ì „ì²´ ë¶„ì„ ë°ì´í„° ë³´ê¸°"):
                st.dataframe(result)
                
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

            st.error("URLì´ ì •í™•í•œì§€, ë˜ëŠ” ì§ë°©ì˜ í˜ì´ì§€ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
